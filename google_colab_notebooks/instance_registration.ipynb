{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30129,
     "status": "ok",
     "timestamp": 1651969818239,
     "user": {
      "displayName": "Zhiang Chen",
      "userId": "14710434422152901796"
     },
     "user_tz": 420
    },
    "id": "Atp-7rHbD50i",
    "outputId": "7541b800-d35b-4e47-912d-c196509f8f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rioxarray\n",
      "  Downloading rioxarray-0.9.1.tar.gz (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 1.3 MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pyproj>=2.2\n",
      "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.3 MB 9.0 MB/s \n",
      "\u001b[?25hCollecting rasterio\n",
      "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.3 MB 1.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: xarray>=0.17 in /usr/local/lib/python3.7/dist-packages (from rioxarray) (0.18.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from rioxarray) (21.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj>=2.2->rioxarray) (2021.10.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from xarray>=0.17->rioxarray) (1.21.6)\n",
      "Requirement already satisfied: setuptools>=40.4 in /usr/local/lib/python3.7/dist-packages (from xarray>=0.17->rioxarray) (57.4.0)\n",
      "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from xarray>=0.17->rioxarray) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->xarray>=0.17->rioxarray) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->xarray>=0.17->rioxarray) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->xarray>=0.17->rioxarray) (1.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->rioxarray) (3.0.8)\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio->rioxarray) (7.1.2)\n",
      "Collecting click-plugins\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting snuggs>=1.4.1\n",
      "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio->rioxarray) (21.4.0)\n",
      "Collecting affine\n",
      "  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n",
      "Collecting cligj>=0.5\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Building wheels for collected packages: rioxarray\n",
      "  Building wheel for rioxarray (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rioxarray: filename=rioxarray-0.9.1-py3-none-any.whl size=54611 sha256=8d965942ca411995e1d4edc209997f90941322f98bf526f3a01a5630681b351e\n",
      "  Stored in directory: /root/.cache/pip/wheels/07/da/9e/1cc57b2e7a29a206893db83e984a341e2e94378263e0798229\n",
      "Successfully built rioxarray\n",
      "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio, pyproj, rioxarray\n",
      "Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 pyproj-3.2.1 rasterio-1.2.10 rioxarray-0.9.1 snuggs-1.4.7\n",
      "Collecting geopandas\n",
      "  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 5.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (3.2.1)\n",
      "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.1.post1)\n",
      "Collecting fiona>=1.8\n",
      "  Downloading Fiona-1.8.21-cp37-cp37m-manylinux2014_x86_64.whl (16.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.7 MB 39.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
      "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
      "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
      "Collecting munch\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.4.0)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.6)\n",
      "Installing collected packages: munch, fiona, geopandas\n",
      "Successfully installed fiona-1.8.21 geopandas-0.10.2 munch-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rioxarray\n",
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1343,
     "status": "ok",
     "timestamp": 1651977867051,
     "user": {
      "displayName": "Zhiang Chen",
      "userId": "14710434422152901796"
     },
     "user_tz": 420
    },
    "id": "zaV_yn46euy5",
    "outputId": "641e9059-6f8d-4846-d46a-dc411cb47933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['instance_registration_IoU_all_adjacents.ipynb',\n",
       " 'data',\n",
       " 'instance_registration.ipynb',\n",
       " 'TGRS',\n",
       " 'instance_registration_IoU.ipynb',\n",
       " 'random_ellipse_shapefile_generation.ipynb',\n",
       " 'tile_splitting.ipynb']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pyproj import CRS\n",
    "from shapely.geometry import Polygon\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from random import shuffle\n",
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "os.chdir('/content/drive/MyDrive/ASU - Zhiang/Projects/instance segmentation/')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiDFevTPD7W8"
   },
   "outputs": [],
   "source": [
    "class Instance_Registration(object):\n",
    "    def __init__(self, instance_dir, \n",
    "                 save_shapefile,\n",
    "                 tif_height_pixel = 1000,\n",
    "                 tif_width_pixel = 1000,\n",
    "                 tif_height_res = -0.01,\n",
    "                 tif_width_res = 0.01,\n",
    "                 tile_overlap_ratio=0.1, \n",
    "                 detection_threshold=0.75, \n",
    "                 segmentation_threshold=0.5, \n",
    "                 iou_threshold=0.5, \n",
    "                 disable_merge=False,\n",
    "                 test=True):\n",
    "        \n",
    "        assert os.path.exists(instance_dir)\n",
    "        self.tile_files = [os.path.join(instance_dir, f) for f in os.listdir(instance_dir) if f.endswith('.pickle')]\n",
    "        self.tile_files.sort()  ########################################################################\n",
    "        self.tiles = {}\n",
    "        self.instances = []  # \n",
    "        tile_data = self._get_instance(self.tile_files[0])\n",
    "        self.test = test\n",
    "        if self.test == True:\n",
    "            _, self.h, self.w = tile_data['masks'].shape\n",
    "        else:\n",
    "            _, _, self.h, self.w = tile_data['masks'].shape\n",
    "        tif_name = tile_data['image_name']\n",
    "        tif = rioxarray.open_rasterio(tif_name)\n",
    "        epsg = tif.rio.crs.to_epsg()\n",
    "        self.crs = CRS(epsg)\n",
    "        #_, self.tiff_h, self.tiff_w = tif.shape\n",
    "        #self.tif_h_size, self.tif_v_size = tif.rio.resolution()\n",
    "        \n",
    "        self.tiff_h, self.tiff_w = tif_height_pixel, tif_width_pixel\n",
    "        self.tif_h_size, self.tif_v_size = tif_width_res, tif_height_res\n",
    "\n",
    "        self.mask_h_size = self.tif_h_size * self.tiff_h / self.h\n",
    "        self.mask_v_size = self.tif_v_size * self.tiff_w / self.w\n",
    "        self.overlap = int(self.h * tile_overlap_ratio)\n",
    "        self.iou_threshold = iou_threshold\n",
    "        dir_path = os.path.dirname(os.path.realpath(tif_name))\n",
    "        tif_name = os.path.join(dir_path, '0_0.tif')\n",
    "        #assert os.path.isfile(tif_name)\n",
    "        #tif = rioxarray.open_rasterio(tif_name)\n",
    "        #self.h_start, self.v_start, _, _= tif.rio.bounds()\n",
    "        self.h_start, self.v_start = 0, 0\n",
    "\n",
    "        self.save_shapefile = save_shapefile\n",
    "        self.detection_threshold = detection_threshold\n",
    "        self.segmentation_threshold = segmentation_threshold\n",
    "        self.disable_merge = disable_merge\n",
    "        self.twins = []\n",
    "        self.instance_num = 0\n",
    "        \n",
    "        \n",
    "    def start_registration(self):\n",
    "        updated_tile_files = []\n",
    "        timestamps = []\n",
    "        self.instances = []\n",
    "        self.tiles = {}\n",
    "        print(\"Instance registration: \")\n",
    "        start_time = time.time()\n",
    "        for tile_file in tqdm(self.tile_files):\n",
    "            tile_data = self._get_instance(tile_file)\n",
    "            masks = tile_data['masks']\n",
    "            instance_N = masks.shape[0]\n",
    "            if instance_N == 0:\n",
    "                continue\n",
    "            updated_tile_files.append(tile_file)\n",
    "            if not self.test:\n",
    "                masks = np.squeeze(masks, axis=1)\n",
    "            tif_name = tile_data['image_name']\n",
    "            tile_indices = tuple([int(i) for i in tif_name.split('/')[-1].split('.')[0].split('_')])\n",
    "            # post processing: detection confidence filter\n",
    "            detect_scores = tile_data['scores']\n",
    "            id_strs = tile_data['ids']  ########################################################\n",
    "            # prune data by detection_threshold\n",
    "            masks = masks[detect_scores>self.detection_threshold]\n",
    "            detect_scores = detect_scores[detect_scores>self.detection_threshold]\n",
    "            id_strs = id_strs[detect_scores>self.detection_threshold]  ######################################################## \n",
    "            tif = rioxarray.open_rasterio(tif_name) \n",
    "            for idx, mask in enumerate(masks):\n",
    "                # post processing: segmentation confidence filter\n",
    "                mask = mask > self.segmentation_threshold\n",
    "                # post processing: contour analysis\n",
    "                contours, _ = cv2.findContours(mask.astype(np.uint8).copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "                if len(contours) > 1:\n",
    "                    areas = [cv2.contourArea(cnt) for cnt in contours]\n",
    "                    i = np.argmax(areas)\n",
    "                    contour = contours[i]\n",
    "                    mask = np.zeros_like(mask).astype(np.uint8)\n",
    "                    cv2.fillPoly(mask, pts =[contour], color=(255))\n",
    "                    local_mask = mask > 0\n",
    "                else:\n",
    "                    contour = contours[0]\n",
    "                    local_mask = mask\n",
    "                # get location using pixel coords: top, bottom, left, right, middle, top-left, top-right, bottom-left, bottom-right\n",
    "                contour = np.squeeze(contour, axis=1)\n",
    "                locations = self._get_locations(contour, local_mask, tile_indices)\n",
    "                # convert masks to global mask\n",
    "                global_mask = self._convert_global_mask(local_mask, tile_indices)\n",
    "                # get global bbox\n",
    "                global_bbox = self._get_global_bbox(global_mask)\n",
    "                # instance registration\n",
    "                instance = {'locations': locations, \n",
    "                            'score': detect_scores[idx], \n",
    "                            'global_bbox': global_bbox, \n",
    "                            'global_mask': global_mask,\n",
    "                            'id_str': id_strs[idx],}\n",
    "\n",
    "                if self.disable_merge:\n",
    "                    self.instances.append(instance)\n",
    "                else:\n",
    "                    self._instance_registration(instance)\n",
    "            timestamps.append(time.time() - start_time)\n",
    "\n",
    "        self.instance_num = len(self.instances)\n",
    "        self.clean_twin_instances()   \n",
    "        print(\"Instance #: \", self.instance_num)\n",
    "        return updated_tile_files, timestamps\n",
    "    \n",
    "    \n",
    "    def update_tile_files(self, updated_tile_files):\n",
    "        self.tile_files = updated_tile_files\n",
    "    \n",
    "                \n",
    "    def save(self):\n",
    "        print('save shapefile: ')\n",
    "        dataframesList = []\n",
    "        for instance in tqdm(self.instances):\n",
    "            if instance is None:\n",
    "                continue\n",
    "            geodataframe = gpd.GeoDataFrame(pd.DataFrame({'score': [instance['score']], 'id': instance['id_str']}), \n",
    "                                           crs=self.crs, \n",
    "                                           geometry=[self._convert_mask_to_poly(instance)])\n",
    "            dataframesList.append(geodataframe)\n",
    "        rdf = gpd.GeoDataFrame(pd.concat(dataframesList, ignore_index=True))\n",
    "        rdf.to_file(self.save_shapefile)\n",
    "                \n",
    "    def _instance_registration(self, instance):\n",
    "\n",
    "        (x,y) = list(instance['locations'].keys())[0]\n",
    "        if 'middle' in instance['locations'][(x, y)].keys():\n",
    "            self._add_instance(instance)\n",
    "            return None\n",
    "        \n",
    "        merged = []\n",
    "        for location in instance['locations'][(x, y)]:\n",
    "            if location == 'left':\n",
    "                adjacent_indices = (x-1, y)\n",
    "                adjacent_location = 'right'\n",
    "                merged.append(self._merge_instance(instance, location, adjacent_indices, adjacent_location))\n",
    "            if location == 'right':\n",
    "                adjacent_indices = (x+1, y)\n",
    "                adjacent_location = 'left'\n",
    "                merged.append(self._merge_instance(instance, location, adjacent_indices, adjacent_location))\n",
    "            if location == 'top':\n",
    "                adjacent_indices = (x, y+1)\n",
    "                adjacent_location = 'bottom'\n",
    "                merged.append(self._merge_instance(instance, location, adjacent_indices, adjacent_location))\n",
    "            if location == 'bottom':\n",
    "                adjacent_indices = (x, y-1)\n",
    "                adjacent_location = 'top'\n",
    "                merged.append(self._merge_instance(instance, location, adjacent_indices, adjacent_location))\n",
    "            if location == 'top-left':\n",
    "                adjacent_indices = (x-1, y+1)\n",
    "                adjacent_location = 'bottom-right'\n",
    "                merged.append(self._merge_instance(instance, location, adjacent_indices, adjacent_location))\n",
    "            if location == 'top-right':\n",
    "                adjacent_indices = (x+1, y+1)\n",
    "                adjacent_location = 'bottom-left'\n",
    "                merged.append(self._merge_instance(instance, location, adjacent_indices, adjacent_location))\n",
    "            if location == 'bottom-left':\n",
    "                adjacent_indices = (x-1, y-1)\n",
    "                adjacent_location = 'top-right'\n",
    "                merged.append(self._merge_instance(instance, location, adjacent_indices, adjacent_location))\n",
    "            if location == 'bottom-right':\n",
    "                adjacent_indices = (x+1, y-1)\n",
    "                adjacent_location = 'top-left'\n",
    "                merged.append(self._merge_instance(instance, location, adjacent_indices, adjacent_location))\n",
    "                \n",
    "        merged = np.array(merged)\n",
    "        merged_num = np.unique(merged[merged>=0]).shape[0]\n",
    "        if merged_num == 0:\n",
    "            self._add_instance(instance)\n",
    "        elif merged_num > 1:\n",
    "            self.twins.append(np.unique(merged[merged>=0]))\n",
    "            \n",
    "                \n",
    "    def _add_instance(self, instance):\n",
    "        self.instances.append(instance)\n",
    "        instance_id = len(self.instances) - 1\n",
    "        # update tile table\n",
    "        tile_indices = list(instance['locations'].keys())[0]\n",
    "        if not self.tiles.get(tile_indices, False):\n",
    "            # initialize tile\n",
    "            empty_locations = {'left':[], 'right':[], 'top':[], 'bottom':[], 'middle':[], 'top-left':[], 'top-right':[], 'bottom-left':[], 'bottom-right':[]}\n",
    "            self.tiles[tile_indices] = empty_locations\n",
    "        # update tile\n",
    "        tile_indices = list(instance['locations'].keys())[0]\n",
    "        for location in instance['locations'][tile_indices].keys():\n",
    "            self.tiles[tile_indices][location].append(instance_id)\n",
    "                        \n",
    "    def _merge_instance(self, instance, location, adjacent_indices, adjacent_location):\n",
    "        if not self.tiles.get(adjacent_indices, False): \n",
    "            return -1\n",
    "        else:\n",
    "            for adjacent_id in self.tiles[adjacent_indices][adjacent_location]:\n",
    "                adjacent_instance = self.instances[adjacent_id]\n",
    "                if self._bbox_intersection(instance['global_bbox'], adjacent_instance['global_bbox']):\n",
    "                    tile_indices = list(instance['locations'].keys())[0]\n",
    "                    mask1 = instance['locations'][tile_indices][location]\n",
    "                    mask2 = adjacent_instance['locations'][adjacent_indices].get(adjacent_location, None)\n",
    "                    iou = self._mask_IoU(mask1, mask2)\n",
    "                    if iou > self.iou_threshold:\n",
    "                        merged_mask = np.concatenate((instance['global_mask'], adjacent_instance['global_mask']))\n",
    "                        merged_mask = np.unique(merged_mask, axis=0)\n",
    "                        merged_mask = tuple(map(tuple, merged_mask))\n",
    "\n",
    "                        self.instances[adjacent_id]['global_mask'] = merged_mask\n",
    "                        self.instances[adjacent_id]['global_bbox'] = self._get_global_bbox(merged_mask)\n",
    "                        self.instances[adjacent_id]['score'] = np.max((self.instances[adjacent_id]['score'], instance['score']))\n",
    "                        self.instances[adjacent_id]['id_str'] += ','+ instance['id_str'] ########################################################\n",
    "                        merged_mask_partial = np.concatenate((mask1, mask2))\n",
    "                        merged_mask_partial = np.unique(merged_mask_partial, axis=0)\n",
    "                        merged_mask_partial = tuple(map(tuple, merged_mask_partial))\n",
    "\n",
    "                        # after merging, instance belongs to multiple tiles. instance's new tile should be updated\n",
    "                        if self.instances[adjacent_id]['locations'].get(tile_indices, False):\n",
    "                            if self.instances[adjacent_id]['locations'][tile_indices].get(location, False):\n",
    "                                existing_mask = self.instances[adjacent_id]['locations'][tile_indices][location]\n",
    "                                temp_mask = np.concatenate((existing_mask, merged_mask_partial))\n",
    "                                temp_mask = np.unique(temp_mask, axis=0)\n",
    "                                temp_mask = tuple(map(tuple, temp_mask))\n",
    "                                self.instances[adjacent_id]['locations'][tile_indices][location] = temp_mask\n",
    "                            else:\n",
    "                                self.instances[adjacent_id]['locations'][tile_indices] = {location: merged_mask_partial}\n",
    "                        else:\n",
    "                            self.instances[adjacent_id]['locations'][tile_indices] = {}\n",
    "                            for loc, mask_partial in instance['locations'][tile_indices].items():\n",
    "                                if loc == location:\n",
    "                                    self.instances[adjacent_id]['locations'][tile_indices][location] = merged_mask_partial\n",
    "                                else:\n",
    "                                    self.instances[adjacent_id]['locations'][tile_indices][loc] = mask_partial\n",
    "\n",
    "                            \n",
    "                        \n",
    "                        # tile is also expanded as instance merge\n",
    "                        if not self.tiles.get(tile_indices, False):\n",
    "                            empty_locations = {'left':[], 'right':[], 'top':[], 'bottom':[], 'middle':[], 'top-left':[], 'top-right':[], 'bottom-left':[], 'bottom-right':[]}\n",
    "                            self.tiles[tile_indices] = empty_locations\n",
    "                        for location in instance['locations'][tile_indices].keys():\n",
    "                            self.tiles[tile_indices][location].append(adjacent_id)\n",
    "                        return adjacent_id   \n",
    "        return -1\n",
    "\n",
    "    def clean_twin_instances(self):\n",
    "        for twins in self.twins:\n",
    "            twins.sort()\n",
    "            for i in twins[1:]:\n",
    "                self.merge_twins(twins[0], i)\n",
    "    \n",
    "    def merge_twins(self, id1, id2):\n",
    "        instance1 = self.instances[id1]\n",
    "        instance2 = self.instances[id2]\n",
    "        mask1 = instance1['global_mask']\n",
    "        mask2 = instance2['global_mask']\n",
    "        merged_mask = np.concatenate((mask1, mask2))\n",
    "        merged_mask = np.unique(merged_mask, axis=0)\n",
    "        merged_mask = tuple(map(tuple, merged_mask))\n",
    "        self.instances[id1]['global_mask'] = merged_mask\n",
    "        self.instances[id1]['global_bbox'] = self._get_global_bbox(merged_mask)\n",
    "        self.instances[id2] = None\n",
    "        self.instance_num -= 1\n",
    "\n",
    "    def _mask_IoU(self, mask1, mask2):\n",
    "        if mask2 == None:\n",
    "            return -1\n",
    "        mask_hash1 = [hash(mask_indices) for mask_indices in mask1]\n",
    "        mask_hash2 = [hash(mask_indices) for mask_indices in mask2]\n",
    "        intersection = np.count_nonzero(np.in1d(mask_hash1, mask_hash2, assume_unique=True))\n",
    "        union = np.unique(mask_hash1 + mask_hash2).shape[0]\n",
    "        return intersection / union\n",
    "\n",
    "    def _mask_intersection_hash_method(self, mask1, mask2):\n",
    "        mask_hash1 = [hash(mask_indices) for mask_indices in mask1]\n",
    "        mask_hash2 = [hash(mask_indices) for mask_indices in mask2]\n",
    "        return -np.count_nonzero(np.in1d(mask_hash1, mask_hash2, assume_unique=True)) * self.mask_h_size * self.mask_v_size\n",
    "    \n",
    "    def _mask_intersection_brute_force_method(self, mask1, mask2):\n",
    "        overlap = len([px for px in mask1 if px in mask2])\n",
    "        return -overlap * self.mask_h_size * self.mask_v_size\n",
    "    \n",
    "        \n",
    "    def _convert_global_mask(self, mask, tile_indices):\n",
    "        x = tile_indices[0] * (self.w - self.overlap)\n",
    "        y = tile_indices[1] * (self.h - self.overlap) + self.h\n",
    "        return tuple([(x+i, y-j) for j,i in np.asarray(np.nonzero(mask)).transpose()])\n",
    "    \n",
    "    def _get_global_bbox(self, mask):\n",
    "        xmin, ymin = np.asarray(mask).min(axis=0)\n",
    "        xmax, ymax = np.asarray(mask).max(axis=0)\n",
    "        return [xmin, ymin, xmax, ymax]\n",
    "    \n",
    "    def _bbox_intersection(self, bbox1, bbox2):\n",
    "        (xmin_a, ymin_a, xmax_a, ymax_a) = bbox1\n",
    "        (xmin_b, ymin_b, xmax_b, ymax_b) = bbox2\n",
    "        if xmin_a < xmax_b <= xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            return True\n",
    "        elif xmin_a <= xmin_b < xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            return True\n",
    "        elif xmin_b < xmax_a <= xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            return True\n",
    "        elif xmin_b <= xmin_a < xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def _get_instance(self, tile_file):\n",
    "        with open(tile_file, 'rb') as handle:\n",
    "            tile_data = pickle.load(handle)\n",
    "        return tile_data\n",
    "    \n",
    "    def _get_locations(self, contour, local_mask, tile_indices):\n",
    "        x1, y1 = np.min(contour, axis=0)\n",
    "        x2, y2 = np.max(contour, axis=0)\n",
    "        locations = {}\n",
    "        if x1 < self.overlap:\n",
    "            mask = local_mask.copy()\n",
    "            mask[:, self.overlap:] = 0\n",
    "            mask_global = self._convert_global_mask(mask, tile_indices)\n",
    "            locations['left'] = mask_global\n",
    "        if x2 > self.h - self.overlap:\n",
    "            mask = local_mask.copy()\n",
    "            mask[:, :-self.overlap] = 0\n",
    "            mask_global = self._convert_global_mask(mask, tile_indices)\n",
    "            locations['right'] = mask_global\n",
    "        if y1 < self.overlap:\n",
    "            mask = local_mask.copy()\n",
    "            mask[self.overlap:,:] = 0\n",
    "            mask_global = self._convert_global_mask(mask, tile_indices)\n",
    "            locations['top'] = mask_global\n",
    "        if y2 > self.w - self.overlap:\n",
    "            mask = local_mask.copy()\n",
    "            mask[:-self.overlap, :] = 0\n",
    "            mask_global = self._convert_global_mask(mask, tile_indices)\n",
    "            locations['bottom'] = mask_global\n",
    "        if len(locations) == 0:\n",
    "            mask = local_mask.copy()\n",
    "            mask_global = self._convert_global_mask(mask, tile_indices)\n",
    "            locations['middle'] = mask_global\n",
    "        \n",
    "        location_list = locations.keys()\n",
    "        if ('left' in location_list) & ('top' in location_list):\n",
    "            mask = local_mask.copy()\n",
    "            mask[:, self.overlap:] = 0\n",
    "            mask[self.overlap:,:] = 0\n",
    "            mask_global = self._convert_global_mask(mask, tile_indices)\n",
    "            locations['top-left'] = mask_global\n",
    "\n",
    "        if ('left' in location_list) & ('bottom' in location_list):\n",
    "            mask = local_mask.copy()\n",
    "            mask[:, self.overlap:] = 0\n",
    "            mask[:-self.overlap, :] = 0\n",
    "            mask_global = self._convert_global_mask(mask, tile_indices)\n",
    "            locations['bottom-left'] = mask_global\n",
    "            \n",
    "        if ('right' in location_list) & ('top' in location_list):\n",
    "            mask = local_mask.copy()\n",
    "            mask[:, :-self.overlap] = 0\n",
    "            mask[self.overlap:,:] = 0\n",
    "            mask_global = self._convert_global_mask(mask, tile_indices)\n",
    "            locations['top-right'] = mask_global\n",
    "\n",
    "        if ('right' in location_list) & ('bottom' in location_list):\n",
    "            mask = local_mask.copy()\n",
    "            mask[:, :-self.overlap] = 0\n",
    "            mask[:-self.overlap, :] = 0\n",
    "            mask_global = self._convert_global_mask(mask, tile_indices)\n",
    "            locations['bottom-right'] = mask_global\n",
    "\n",
    "        return {tile_indices: locations}\n",
    "        \n",
    "        \n",
    "    def _convert_mask_to_poly(self, instance):\n",
    "        mask = np.asarray(instance['global_mask'])\n",
    "        bbox = instance['global_bbox']\n",
    "        bottom_left = np.asarray(mask).min(axis=0)\n",
    "        local_mask = mask - bottom_left\n",
    "        #print(local_mask.min(axis=0))\n",
    "        #print(local_mask.max(axis=0))\n",
    "        mask_shape = (int(bbox[2] - bbox[0]) + 1, int(bbox[3] - bbox[1]) + 1)  \n",
    "        local_mask = self._create_bool_mask(local_mask, mask_shape)\n",
    "        contours, _ = cv2.findContours(local_mask.astype(np.uint8).copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        assert len(contours) == 1\n",
    "        contour = np.asarray(contours[0]) + bottom_left\n",
    "        contour = contour.reshape(-1, 2).tolist()\n",
    "        coords = [(self.h_start + pixel[0]*self.mask_h_size, \n",
    "                   self.v_start - pixel[1]*self.mask_v_size) \n",
    "                  for pixel in contour]\n",
    "        coords = np.asarray(coords)\n",
    "        poly = Polygon(zip(coords[:, 0].tolist(), coords[:, 1].tolist()))\n",
    "        return poly\n",
    "\n",
    "        \n",
    "    def _create_bool_mask(self, mask, size):\n",
    "        \"\"\"\n",
    "        :param mask: mask by index\n",
    "        :param size: size of image\n",
    "        :return: bool mask\n",
    "        \"\"\"\n",
    "        mask_ = np.zeros(size)\n",
    "        mask = mask.tolist()\n",
    "        for x, y in mask:\n",
    "            #if (x < size[0]) & (y < size[1]):\n",
    "            mask_[int(x), int(y)] = 1\n",
    "        return mask_.transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k94otWqsE1pX"
   },
   "outputs": [],
   "source": [
    "ir = Instance_Registration('data/random_generation/split/', \n",
    "                           'data/random_generation/merged_400_3.shp', \n",
    "                           iou_threshold=0.88, \n",
    "                           disable_merge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 348445,
     "status": "ok",
     "timestamp": 1651994842275,
     "user": {
      "displayName": "Zhiang Chen",
      "userId": "14710434422152901796"
     },
     "user_tz": 420
    },
    "id": "lqrdi4OgFCbi",
    "outputId": "07e68c18-f938-4ec0-c5ff-0cb2b6c4c79a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance registration: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [04:53<00:00, 18.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance #:  3600\n",
      "save shapefile: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3605/3605 [00:49<00:00, 72.15it/s]\n"
     ]
    }
   ],
   "source": [
    "updated_tile_files, timestamps = ir.start_registration()\n",
    "ir.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1651994842276,
     "user": {
      "displayName": "Zhiang Chen",
      "userId": "14710434422152901796"
     },
     "user_tz": 420
    },
    "id": "GG0H3mBlPP6T",
    "outputId": "c723f715-7005-444a-f008-5171ec09b207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1823, 2546]),\n",
       " array([1951, 2707]),\n",
       " array([2859, 3453]),\n",
       " array([2931, 3459]),\n",
       " array([3187, 3512])]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnWUpN2RF5dS"
   },
   "outputs": [],
   "source": [
    "## if save failed\n",
    "\"\"\"\n",
    "test = Instance_Registration('data/random_generation/split/', \n",
    "                           'data/random_generation/merged_15_5.shp', \n",
    "                           disable_merge=False)\n",
    "\n",
    "test.instances = ir.instances[1:]\n",
    "test.save()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqNBIyNXf8Ac"
   },
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NUSXJMQ7ZrL"
   },
   "source": [
    "$Accuracy = \\frac{TP+TN}{TP+TN+FP+TN}$  \n",
    "$Precision = \\frac{TP}{TP+FP}$  \n",
    "$Recall = \\frac{TP}{TP+FN}$  \n",
    "\n",
    "Positive indicates merged and negative indicates unmerged in the resulted shapefile. \n",
    "\n",
    "$TP$: (1) $merged_i = merged_j$ for all {i, j} in merged ids, **and** (2) $IoU(ground\\_truth, merged) > C$ \n",
    "\n",
    "$TN$: $IoU(ground\\_truth, unmerged) > C$\n",
    "\n",
    "$FP$: (1) $merged_i \\neq merged_j$ for any {i, j} in merged ids, **or** (2) $IoU(ground\\_truth, merged) \\leq C$\n",
    "\n",
    "$FN$: $IoU(ground\\_truth, unmerged)\\leq C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEjJ3PP3f51t"
   },
   "outputs": [],
   "source": [
    "def IoU(poly1, poly2):\n",
    "    i = poly1.intersection(poly2).area\n",
    "    u = poly1.union(poly2).area\n",
    "    return i/u\n",
    "\n",
    "def uniqueness(TP, TN):\n",
    "    a = TP + TN\n",
    "    unq, unq_idx, unq_cnt = np.unique(a, return_inverse=True, return_counts=True)\n",
    "    cnt_mask = unq_cnt > 1\n",
    "    dup_ids = unq[cnt_mask]\n",
    "    cnt_idx, = np.nonzero(cnt_mask)\n",
    "    idx_mask = np.in1d(unq_idx, cnt_idx)\n",
    "    idx_idx, = np.nonzero(idx_mask)\n",
    "    srt_idx = np.argsort(unq_idx[idx_mask])\n",
    "    dup_idx = np.split(idx_idx[srt_idx], np.cumsum(unq_cnt[cnt_mask])[:-1])\n",
    "    duplicated_ids = [a[i[0]] for i in dup_idx if i.size !=0]\n",
    "    return duplicated_ids\n",
    "\n",
    "def evaluate(groundtruth_shapefile, merged_shapefile, IoU_threshold=0.88):\n",
    "    assert os.path.exists(groundtruth_shapefile)\n",
    "    assert os.path.exists(merged_shapefile)\n",
    "    gt_shp = gpd.read_file(groundtruth_shapefile)\n",
    "    merged_shp = gpd.read_file(merged_shapefile)\n",
    "    N, _ = merged_shp.shape\n",
    "    TP = []\n",
    "    FP = []\n",
    "    TN = []\n",
    "    FN = []\n",
    "    for i in range(N):\n",
    "        merged_poly = merged_shp['geometry'][i]\n",
    "        ids = merged_shp['id'][i]\n",
    "        if ',' in ids:\n",
    "            # merged result: postive\n",
    "            ids = [int(id) for id in ids.split(',')]\n",
    "            if np.unique(ids).shape[0] == 1:\n",
    "                id = ids[0]\n",
    "                gt_poly = gt_shp['geometry'][id]\n",
    "                if IoU(gt_poly, merged_poly) > IoU_threshold:\n",
    "                    # true positive\n",
    "                    TP.append(id)\n",
    "                else:\n",
    "                    # false positive\n",
    "                    FP.append(id)\n",
    "            else:\n",
    "                # false positive\n",
    "                FP.append(ids)\n",
    "        else:\n",
    "            # unmerged result: negative\n",
    "            id = int(ids)\n",
    "            gt_poly = gt_shp['geometry'][id]\n",
    "            if IoU(gt_poly, merged_poly) > IoU_threshold:\n",
    "                # true negative\n",
    "                TN.append(id)\n",
    "            else:\n",
    "                # false negative\n",
    "                FN.append(id)\n",
    "    \n",
    "\n",
    "\n",
    "    tp = len(TP)\n",
    "    tn = len(TN)\n",
    "    fp = len(FP)\n",
    "    fn = len(FN)\n",
    "    print(\"total: \", N)\n",
    "    print(\"TP, TN, FP, FN: \", tp, tn, fp, fn)\n",
    "    print(\"FP: \", FP)\n",
    "    print(\"FN: \", FN)\n",
    "    print(\"Duplicated ids: \", uniqueness(TP, TN))\n",
    "    print(\"accuracy: {acc:.2f}%\".format(acc=(tp+tn)/(tp+tn+fp+fn)*100))\n",
    "    print(\"precision: {pre:.2f}%\".format(pre=tp/(tp+fp)*100))\n",
    "    print(\"recall: {rec:.2f}%\".format(rec=tp/(tp+fn)*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5052,
     "status": "ok",
     "timestamp": 1651994857040,
     "user": {
      "displayName": "Zhiang Chen",
      "userId": "14710434422152901796"
     },
     "user_tz": 420
    },
    "id": "t23LtgdDI3ho",
    "outputId": "a51080a2-7364-447f-e169-9f62d3498357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  3600\n",
      "TP, TN, FP, FN:  1208 2391 1 0\n",
      "FP:  [[63, 63, 1788]]\n",
      "FN:  []\n",
      "Duplicated ids:  []\n",
      "accuracy: 99.97%\n",
      "precision: 99.92%\n",
      "recall: 100.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate('data/random_generation/0_0.shp', 'data/random_generation/merged_400_3.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1651994141963,
     "user": {
      "displayName": "Zhiang Chen",
      "userId": "14710434422152901796"
     },
     "user_tz": 420
    },
    "id": "kQ2Ldr8fhgjx",
    "outputId": "847eaac0-e852-4d8b-c3b9-c0f20ec9a64e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1219, 1960])]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.twins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKrTH5EeH6xe"
   },
   "source": [
    "# Intersection comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TafI6SWiMJG4"
   },
   "source": [
    "https://gis.stackexchange.com/questions/411777/how-is-polygon-intersection-implemented-in-jts-shapely\n",
    "\n",
    "https://en.wikipedia.org/wiki/Weiler%E2%80%93Atherton_clipping_algorithm\n",
    "\n",
    "https://stackoverflow.com/questions/2272179/a-simple-algorithm-for-polygon-intersection#:~:text=Compute%20the%20center%20of%20mass,the%20two%20polygons%20%22intersect%22. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98kmmJIQfVG_"
   },
   "outputs": [],
   "source": [
    "!rm data/random_generation/split/*.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1651990117183,
     "user": {
      "displayName": "Zhiang Chen",
      "userId": "14710434422152901796"
     },
     "user_tz": 420
    },
    "id": "nCxCqbbn3866",
    "outputId": "70b4e87d-ca7b-417d-dcb1-79cd110bdab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "merged = [-1, 6, 3, 5, -1]\n",
    "merged = np.array(merged)\n",
    "a = merged[merged>=0]\n",
    "a.sort()\n",
    "for i in a[1:]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1651991747438,
     "user": {
      "displayName": "Zhiang Chen",
      "userId": "14710434422152901796"
     },
     "user_tz": 420
    },
    "id": "gL0pKV-UNAWt",
    "outputId": "1626881b-d4eb-4f9e-91cb-027754cf105c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1j576_1pYQry"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM7ip0B7HL0E6nyKZ4XH1Kf",
   "collapsed_sections": [],
   "name": "instance_registration_IoU_all_adjacents.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
